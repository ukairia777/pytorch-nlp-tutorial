{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V39BhFAekMmg",
        "outputId": "a87195bb-a5ea-4ed5-8894-a2faf37c3ef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.24-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.25-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain_chroma\n",
            "  Downloading langchain_chroma-0.2.4-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.6.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.65 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.65)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.86.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.45)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Collecting chromadb>=1.0.9 (from langchain_chroma)\n",
            "  Downloading chromadb-1.0.13-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (2.11.7)\n",
            "Collecting pybase64>=1.4.1 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (0.34.3)\n",
            "Collecting posthog>=2.4.0 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading posthog-5.3.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (4.14.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (1.73.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (4.24.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (24.2)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.3.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=1.0.9->langchain_chroma) (1.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (0.25.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (3.2.2)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain_chroma) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain_chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain_chroma) (2.33.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (2.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (0.33.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain_chroma) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain_chroma) (1.5.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (1.1.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain_chroma) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (0.1.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (0.6.1)\n",
            "Downloading langchain_openai-0.3.24-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.25-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_chroma-0.2.4-py3-none-any.whl (11 kB)\n",
            "Downloading pypdf-5.6.0-py3-none-any.whl (304 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.2/304.2 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.0.13-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-5.3.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.8/103.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=21da2d9dac0bca19c7adf986437360b800868de1b85698202236c5fdc8090f1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, python-dotenv, pypdf, pybase64, overrides, opentelemetry-proto, mypy-extensions, mmh3, marshmallow, humanfriendly, httpx-sse, httptools, bcrypt, backoff, watchfiles, typing-inspect, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, pydantic-settings, opentelemetry-semantic-conventions, onnxruntime, kubernetes, dataclasses-json, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, langchain_openai, chromadb, langchain_community, langchain_chroma\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.13 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 kubernetes-33.1.0 langchain_chroma-0.2.4 langchain_community-0.3.25 langchain_openai-0.3.24 marshmallow-3.26.1 mmh3-5.1.0 mypy-extensions-1.1.0 onnxruntime-1.22.0 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 overrides-7.7.0 posthog-5.3.0 pybase64-1.4.1 pydantic-settings-2.9.1 pypdf-5.6.0 pypika-0.48.9 python-dotenv-1.1.0 typing-inspect-0.9.0 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_openai langchain_community langchain_chroma pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import json\n",
        "from typing import List\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.schema import Document\n",
        "import requests"
      ],
      "metadata": {
        "id": "fB0NmWgQkQ_z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = '여러분의 키 값'"
      ],
      "metadata": {
        "id": "BTKXKbe3kTOP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 분석할 PDF 파일을 웹에서 다운로드.\n",
        "url = \"https://github.com/llama-index-tutorial/llama-index-tutorial/raw/main/ch07/2023_%EB%B6%81%ED%95%9C%EC%9D%B8%EA%B6%8C%EB%B3%B4%EA%B3%A0%EC%84%9C.pdf\"\n",
        "filename = \"2023_북한인권보고서.pdf\"\n",
        "\n",
        "response = requests.get(url)\n",
        "with open(filename, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(f\"{filename} 다운로드 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSuSX_aCkW0L",
        "outputId": "66f776ae-7a36-4cd6-881b-6f637f22b9ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023_북한인권보고서.pdf 다운로드 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain의 LLM과 임베딩 모델 설정\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)  # GPT-4o를 언어 모델로 사용\n",
        "embed_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")  # 임베딩 모델 사용\n",
        "\n",
        "# 문서 분할 설정\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=300,  # 문서를 300자 단위로 분할\n",
        "    chunk_overlap=100,  # 문맥 유지를 위해 청크 간 100자 중복\n",
        ")\n",
        "\n",
        "# PDF 문서를 읽고 벡터 인덱스 생성\n",
        "loader = PyPDFLoader(\"2023_북한인권보고서.pdf\")  # PDF 문서 로더\n",
        "documents = loader.load()  # 문서에서 텍스트 추출\n",
        "chunks = text_splitter.split_documents(documents)  # 문서 분할\n",
        "vector_store = Chroma.from_documents(chunks, embed_model)  # 추출된 텍스트로 벡터 인덱스 생성"
      ],
      "metadata": {
        "id": "NGBH4Pq6kX5L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DocumentScorer:\n",
        "    # LLM을 사용해 문서의 관련성을 정밀하게 평가하고 점수를 매기는 클래스\n",
        "\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "\n",
        "    def evaluate_document(self, query: str, content: str) -> float:\n",
        "        # LLM을 사용해 문서와 쿼리 간의 의미적 관련성을 1-10점으로 평가\n",
        "        prompt = f\"\"\"\n",
        "        아래 주어진 질문과 문서의 관련성을 평가해주세요.\n",
        "\n",
        "        [평가 기준]\n",
        "        - 문서가 질문에서 요구하는 정보를 직접적으로 포함하면 8-10점\n",
        "        - 문서가 질문과 관련된 맥락을 포함하지만 직접적인 답이 아니면 4-7점\n",
        "        - 문서가 질문과 거의 관련이 없으면 1-3점\n",
        "\n",
        "        [주의사항]\n",
        "        - 단순히 비슷한 단어가 등장하는 것은 높은 점수의 근거가 될 수 없습니다\n",
        "        - 질문의 의도와 문맥을 정확히 파악하여 평가해주세요\n",
        "        - 시간, 장소, 수치 등 구체적인 정보의 일치 여부를 중요하게 고려해주세요\n",
        "\n",
        "        질문: {query}\n",
        "        문서: {content}\n",
        "\n",
        "        응답은 반드시 다음 JSON 형식이어야 합니다. 백틱은 쓰지마십시오.:\n",
        "        {{\"relevance_score\": float}}\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            # LLM에 프롬프트를 전송하고 JSON 형식의 응답을 받음\n",
        "            response = self.llm.invoke(prompt)\n",
        "            # 응답에서 relevance_score 값을 추출\n",
        "            score = json.loads(response.content)[\"relevance_score\"]\n",
        "            # 점수를 float로 변환하여 반환\n",
        "            return float(score)\n",
        "        except Exception as e:\n",
        "            print(f\"Error occurred: {str(e)}\")\n",
        "            return 5.0  # 에러 발생시 중간 점수로 처리하여 시스템 안정성 유지\n",
        "\n",
        "    def postprocess_documents(self, documents: List[Document], query: str) -> List[Document]:\n",
        "        # 벡터 검색으로 찾은 4개 문서를 LLM으로 재평가하여 최적의 2개 선택\n",
        "        print('\\n=== LLM이 4개의 검색 결과에 대해서 관련성을 평가합니다. ===')\n",
        "        scored_docs = []\n",
        "        for doc in documents:\n",
        "            # 현재 처리 중인 문서에서 순수 텍스트 컨텐츠만 추출\n",
        "            content = doc.page_content\n",
        "            # LLM으로 문서 관련성 점수 계산 (1-10 사이 점수)\n",
        "            score = self.evaluate_document(query, content)\n",
        "            # 디버깅/모니터링을 위해 각 문서의 내용과 점수를 출력\n",
        "            print(f\"\\nLLM 기반의 평가:\\n{content}\\n=> 점수: {score}\\n\")\n",
        "            # 현재 문서와 계산된 점수를 튜플로 저장\n",
        "            scored_docs.append((doc, score))\n",
        "\n",
        "        # 모든 문서를 점수 기준 내림차순으로 정렬하고 상위 2개만 선택하여 반환\n",
        "        ranked_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
        "        return [doc for doc, _ in ranked_docs[:2]]"
      ],
      "metadata": {
        "id": "BzDtmXnYkZSB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SemanticRanker:\n",
        "    # 벡터 검색 결과에 LLM 기반 의미적 평가를 적용하여 최적의 문서를 선별하는 시스템\n",
        "\n",
        "    def __init__(self, vector_store, scorer):\n",
        "        # 생성자에서 벡터 검색용 저장소와 LLM 기반 문서 평가기 인스턴스를 받아 저장\n",
        "        self.vector_store = vector_store  # 벡터 검색용 저장소\n",
        "        self.scorer = scorer  # LLM 기반 문서 평가기\n",
        "\n",
        "    def retrieve(self, query: str) -> List[Document]:\n",
        "        # 벡터 검색으로 유사도 기반 후보 문서 4개를 추출하고 LLM으로 재평가\n",
        "        vector_results = self.vector_store.similarity_search(query, k=4)\n",
        "\n",
        "        # 초기 벡터 검색 결과를 디버깅/분석용으로 출력\n",
        "        print(\"\\n=== 실제 검색 결과 (Top 4) ===\")\n",
        "        for i, doc in enumerate(vector_results, 1):\n",
        "            print(f\"\\n검색 문서 {i}:\")\n",
        "            print(doc.page_content)\n",
        "\n",
        "        # LLM으로 문서들을 재평가하고 재정렬하여 최적의 2개 선택\n",
        "        reranked_results = self.scorer.postprocess_documents(vector_results, query)\n",
        "\n",
        "        # 최종 선별된 문서를 디버깅/분석용으로 출력\n",
        "        print(\"\\n=== LLM의 리랭킹 결과 (Top 2) ===\")\n",
        "        for i, doc in enumerate(reranked_results, 1):\n",
        "            print(f\"\\n검색 문서 {i}:\")\n",
        "            print(doc.page_content)\n",
        "\n",
        "        return reranked_results"
      ],
      "metadata": {
        "id": "qoO7k36-kaaL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문서 평가 및 검색 시스템 선언(초기화)\n",
        "scorer = DocumentScorer(llm)  # LLM 기반 문서 평가기 생성\n",
        "ranker = SemanticRanker(vector_store, scorer)  # 벡터 검색과 LLM 평가를 결합한 시스템 생성"
      ],
      "metadata": {
        "id": "xo8TFAJykbb6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 답변 생성 함수\n",
        "def generate_final_answer(query: str, documents: List[Document]) -> str:\n",
        "    context = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
        "\n",
        "    prompt = f\"\"\"다음 검색 결과를 바탕으로 질문에 답변해주세요.\n",
        "    검색 결과의 정보를 최대한 사용하고, 없는 정보는 답변하지 마세요.\n",
        "\n",
        "    검색 결과:\n",
        "    {context}\n",
        "\n",
        "    질문: {query}\n",
        "\n",
        "    답변:\"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    return response.content\n",
        "\n",
        "# 실제 쿼리 실행\n",
        "query = \"19년 말 평양시 소재 기업소에서 달마다 배급받은 음식\"\n",
        "print(f\"\\n질문: {query}\")\n",
        "\n",
        "# 리랭킹을 통해 최적의 문서 2개 선택\n",
        "best_documents = ranker.retrieve(query)\n",
        "\n",
        "# 선택된 문서로 최종 답변 생성\n",
        "final_answer = generate_final_answer(query, best_documents)\n",
        "print(f\"\\n최종 답: {final_answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEQhud9PkchC",
        "outputId": "1d1e3714-43da-49b5-de8b-2ec10391cec1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "질문: 19년 말 평양시 소재 기업소에서 달마다 배급받은 음식\n",
            "\n",
            "=== 실제 검색 결과 (Top 4) ===\n",
            "\n",
            "검색 문서 1:\n",
            "화 또는 쌀이나 기름 등 현물로 지급하였다고 한다. 2019년 평양\n",
            "의 외화벌이 사업소에서는 보수 50달러를 월 2회로 나누어 현금으\n",
            "로 지급하였다고 하는 사례가 있었고, 평양 외화벌이 식당에서는 매\n",
            "\n",
            "검색 문서 2:\n",
            "파악되었다. 따라서 기관·기업소의 상황에 따라 식량배급량, 주기, \n",
            "곡식종류에 상당한 차이가 있는 것으로 나타났다. 외화벌이 기관 등\n",
            "에는 식량배급이 원활하게 이뤄지고 있었다는 증언이 수집되었다. \n",
            "2019년 평양시에서 기업소 운전원으로 일하였던 노동자는 매월 쌀·\n",
            "설탕·기름·야채·돼지고기 등을 배급받아 식량이 부족하지 않았다는 \n",
            "증언과 2019년 중앙당 산하의 기업소에서 매월 쌀 6㎏ 정도, 기름 5\n",
            "ℓ, 설탕 2㎏, 맛내기 2봉지, 돼지고기 2㎏, 닭고기 1마리 정도 받았\n",
            "\n",
            "검색 문서 3:\n",
            "가배급을 선택하고, 잘사는 기업소들은 기업소 자체 배급을 선택합\n",
            "니 다. 세대주가 직장에 다닐 경우 세대주만 직장에서 배급을 받고 \n",
            "가족들은 국가배급소에서 배급을 받습니다. 평양시와 자강도는 대\n",
            "체로 다 줬는데 다른 지역은 배급이 잘 안되고 배급제가 없어졌다는 \n",
            "소리를 들었습니다. ”\n",
            "국가배급의 주기, 양, 곡물의 종류 등에서 평양시와 지방의 차이\n",
            "가 크게 나고 있었다. 식량배급이 비교적 원활하게 작동하는 지역은 \n",
            "평양시로 보이는데, 2017년 어머니가 지역배급 대상자로 배급표가\n",
            "\n",
            "검색 문서 4:\n",
            "한 달을 생활하기에 부족한 금액이었다고 하였다. 2018년 양강도의 \n",
            "무역사업소에서는 1년치 노동 보수와 배급을 한 번에 지급하였다고 \n",
            "하는데, 지급된 금액은 노동자 1명에게 1,800위안으로 약 300만원 \n",
            "정도였다고 하였다. 2019년 양강도의 합영회사는 노동자에게 매달 \n",
            "9~12만원의 보수를 지급하고, 1년에 한번 쌀 25kg을 지급하였다는 \n",
            "진술이 있었다. 또한 2020년 합영회사에서는 보수를 성과만큼 받았\n",
            "다고 하는데, 숙련공은 350위안, 쌀 100kg을 살 수 있을 정도의 돈\n",
            "을 받는 경우도 있었다고 하였다.\n",
            "\n",
            "=== LLM이 4개의 검색 결과에 대해서 관련성을 평가합니다. ===\n",
            "\n",
            "LLM 기반의 평가:\n",
            "화 또는 쌀이나 기름 등 현물로 지급하였다고 한다. 2019년 평양\n",
            "의 외화벌이 사업소에서는 보수 50달러를 월 2회로 나누어 현금으\n",
            "로 지급하였다고 하는 사례가 있었고, 평양 외화벌이 식당에서는 매\n",
            "=> 점수: 3.0\n",
            "\n",
            "\n",
            "LLM 기반의 평가:\n",
            "파악되었다. 따라서 기관·기업소의 상황에 따라 식량배급량, 주기, \n",
            "곡식종류에 상당한 차이가 있는 것으로 나타났다. 외화벌이 기관 등\n",
            "에는 식량배급이 원활하게 이뤄지고 있었다는 증언이 수집되었다. \n",
            "2019년 평양시에서 기업소 운전원으로 일하였던 노동자는 매월 쌀·\n",
            "설탕·기름·야채·돼지고기 등을 배급받아 식량이 부족하지 않았다는 \n",
            "증언과 2019년 중앙당 산하의 기업소에서 매월 쌀 6㎏ 정도, 기름 5\n",
            "ℓ, 설탕 2㎏, 맛내기 2봉지, 돼지고기 2㎏, 닭고기 1마리 정도 받았\n",
            "=> 점수: 9.0\n",
            "\n",
            "\n",
            "LLM 기반의 평가:\n",
            "가배급을 선택하고, 잘사는 기업소들은 기업소 자체 배급을 선택합\n",
            "니 다. 세대주가 직장에 다닐 경우 세대주만 직장에서 배급을 받고 \n",
            "가족들은 국가배급소에서 배급을 받습니다. 평양시와 자강도는 대\n",
            "체로 다 줬는데 다른 지역은 배급이 잘 안되고 배급제가 없어졌다는 \n",
            "소리를 들었습니다. ”\n",
            "국가배급의 주기, 양, 곡물의 종류 등에서 평양시와 지방의 차이\n",
            "가 크게 나고 있었다. 식량배급이 비교적 원활하게 작동하는 지역은 \n",
            "평양시로 보이는데, 2017년 어머니가 지역배급 대상자로 배급표가\n",
            "=> 점수: 4.0\n",
            "\n",
            "\n",
            "LLM 기반의 평가:\n",
            "한 달을 생활하기에 부족한 금액이었다고 하였다. 2018년 양강도의 \n",
            "무역사업소에서는 1년치 노동 보수와 배급을 한 번에 지급하였다고 \n",
            "하는데, 지급된 금액은 노동자 1명에게 1,800위안으로 약 300만원 \n",
            "정도였다고 하였다. 2019년 양강도의 합영회사는 노동자에게 매달 \n",
            "9~12만원의 보수를 지급하고, 1년에 한번 쌀 25kg을 지급하였다는 \n",
            "진술이 있었다. 또한 2020년 합영회사에서는 보수를 성과만큼 받았\n",
            "다고 하는데, 숙련공은 350위안, 쌀 100kg을 살 수 있을 정도의 돈\n",
            "을 받는 경우도 있었다고 하였다.\n",
            "=> 점수: 2.0\n",
            "\n",
            "\n",
            "=== LLM의 리랭킹 결과 (Top 2) ===\n",
            "\n",
            "검색 문서 1:\n",
            "파악되었다. 따라서 기관·기업소의 상황에 따라 식량배급량, 주기, \n",
            "곡식종류에 상당한 차이가 있는 것으로 나타났다. 외화벌이 기관 등\n",
            "에는 식량배급이 원활하게 이뤄지고 있었다는 증언이 수집되었다. \n",
            "2019년 평양시에서 기업소 운전원으로 일하였던 노동자는 매월 쌀·\n",
            "설탕·기름·야채·돼지고기 등을 배급받아 식량이 부족하지 않았다는 \n",
            "증언과 2019년 중앙당 산하의 기업소에서 매월 쌀 6㎏ 정도, 기름 5\n",
            "ℓ, 설탕 2㎏, 맛내기 2봉지, 돼지고기 2㎏, 닭고기 1마리 정도 받았\n",
            "\n",
            "검색 문서 2:\n",
            "가배급을 선택하고, 잘사는 기업소들은 기업소 자체 배급을 선택합\n",
            "니 다. 세대주가 직장에 다닐 경우 세대주만 직장에서 배급을 받고 \n",
            "가족들은 국가배급소에서 배급을 받습니다. 평양시와 자강도는 대\n",
            "체로 다 줬는데 다른 지역은 배급이 잘 안되고 배급제가 없어졌다는 \n",
            "소리를 들었습니다. ”\n",
            "국가배급의 주기, 양, 곡물의 종류 등에서 평양시와 지방의 차이\n",
            "가 크게 나고 있었다. 식량배급이 비교적 원활하게 작동하는 지역은 \n",
            "평양시로 보이는데, 2017년 어머니가 지역배급 대상자로 배급표가\n",
            "\n",
            "최종 답: 2019년 말 평양시 소재 기업소에서 일하던 노동자는 매월 쌀 6㎏, 기름 5ℓ, 설탕 2㎏, 맛내기 2봉지, 돼지고기 2㎏, 닭고기 1마리를 배급받았습니다.\n"
          ]
        }
      ]
    }
  ]
}