# -*- coding: utf-8 -*-
"""챗 템플릿(Chat Template) - wikidocs 25-06-20.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u_bBOzlJqbVhWS9LFlvfp4WKPGnHfDL6
"""

from transformers import AutoTokenizer

model_id = "allganize/Llama-3-Alpha-Ko-8B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(model_id)

# 토큰화 과정을 내부적으로 수행 후에 바로 인코딩 한 결과
tokenizer.encode('안녕하세요. 반갑습니다.')

tokenizer.decode([128000, 101193, 124409, 13, 64857, 115072, 39331, 13])

messages = [
    {"role": "system", "content": "당신은 인공지능 어시스턴트입니다. 묻는 말에 친절하고 정확하게 답변하세요."},
    {"role": "user", "content": "은행의 기준 금리에 대해서 설명해줘"}
]

# tokenizer=False는 인코딩은 안 하고 챗 템플릿만 적용
template_messages = tokenizer.apply_chat_template(messages, tokenize=False)
print(template_messages)

encodeds = tokenizer.apply_chat_template(messages)
print('템플릿 적용 및 정수 인코딩 후:\n', encodeds)

print('템플릿 적용 및 정수 인코딩 결과를 복원:\n',tokenizer.decode((encodeds)))

encodeds = tokenizer.apply_chat_template(messages, add_generation_prompt=True)
print(encodeds)

print('템플릿 적용 및 정수 인코딩 결과를 복원:\n',tokenizer.decode((encodeds)))